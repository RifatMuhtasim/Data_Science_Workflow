{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYauQ9I6yn4Bw+1tzQJx4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/Data_Science_Workflow/blob/main/5.1.Optuna_Regression_Hyperparameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIGKFZTG49up"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import optuna\n",
        "except:\n",
        "    !pip install --quiet optuna\n",
        "    import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(X, y):\n",
        "    reg = LinearRegression()\n",
        "    mse_scores = -cross_val_score(\n",
        "        reg, X, y, scoring='neg_mean_squared_error', cv=5, n_jobs=-1\n",
        "    )  # Get negative mean squared error scores.\n",
        "    rmse_scores = np.sqrt(mse_scores)\n",
        "    return rmse_scores.mean()\n",
        "\n",
        "rmse_result = objective(X, y)\n",
        "print(f\"RMSE: {rmse_result}\")"
      ],
      "metadata": {
        "id": "3Ql8w3Iv5Np3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Multiple Model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "def objective(X, y, model):\n",
        "    reg = model\n",
        "\n",
        "    mse_scores = -cross_val_score(\n",
        "        reg, X, y, scoring='neg_mean_squared_error', cv=5, n_jobs=-1\n",
        "    )  # Get negative mean squared error scores.\n",
        "    rmse_scores = np.sqrt(mse_scores)\n",
        "    return rmse_scores.mean()\n",
        "\n",
        "\n",
        "models = {'Linear_Regression':  LinearRegression(),\n",
        "                    'Random_Forest': RandomForestRegressor(),\n",
        "                    'Decision_Tree': DecisionTreeRegressor(),\n",
        "                    'XGB_Regressor': XGBRegressor(),\n",
        "                    'SVM': SVR(),\n",
        "                    'KNearest_Neighbors': KNeighborsRegressor()}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    result = objective(X, y, model=model)\n",
        "    print(f\"{model_name} RMSE is: \", result)"
      ],
      "metadata": {
        "id": "F5D4Kiw25OJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Optuna"
      ],
      "metadata": {
        "id": "EVUbwSnb5SPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "\n",
        "import optuna\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def LinearRegression_Optuna(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        params = {\n",
        "            'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False])\n",
        "        }\n",
        "\n",
        "        clf = LinearRegression(**params)\n",
        "        mse_scores = -cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = LinearRegression_Optuna(X, y)\n",
        "print(f\"Linear Regression RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")"
      ],
      "metadata": {
        "id": "I76m-AE75P93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  XGBRegressor\n",
        "\n",
        "import optuna\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def XGBRegressor_Optuna(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 100, log=True),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 100, log=True),\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "\n",
        "        clf = XGBRegressor(**params)\n",
        "        mse_scores = -cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = XGBRegressor_Optuna(X, y)\n",
        "print(f\"XGBoost Regressor RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")"
      ],
      "metadata": {
        "id": "bOdffJna5UCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeRegressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def DecisionTreeRegressor_Optuna(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        params = {\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "            'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None]),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        clf = DecisionTreeRegressor(**params)\n",
        "        mse_scores = -cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = DecisionTreeRegressor_Optuna(X, y)\n",
        "print(f\"DecisionTreeRegressor RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")"
      ],
      "metadata": {
        "id": "LmzChFi65abI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestRegressor\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "def RandomForestRegressor_Optuna(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "            'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        clf = RandomForestRegressor(**params)\n",
        "        mse_scores = -cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = RandomForestRegressor_Optuna(X, y)\n",
        "print(f\"RandomForestRegressor RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")\n"
      ],
      "metadata": {
        "id": "eNaOxagn5cMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVR\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "def SVMRegressor_Optuna(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        params = {\n",
        "            'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "            'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
        "            'epsilon': trial.suggest_float('epsilon', 1e-3, 1e1, log=True),\n",
        "        }\n",
        "        if params['kernel'] == 'poly':\n",
        "            params['degree'] = trial.suggest_int('degree', 2, 5)\n",
        "        if params['kernel'] in ['poly', 'rbf', 'sigmoid']:\n",
        "            params['gamma'] = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
        "\n",
        "        svr = SVR(**params)\n",
        "        mse_scores = -cross_val_score(svr, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = SVMRegressor_Optuna(X, y)\n",
        "print(f\"SVM Regressor RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")\n"
      ],
      "metadata": {
        "id": "bx8Schgk5eEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNeighborsRegressor\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "def KNNRegressor_Optuna(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        params = {\n",
        "            'n_neighbors': trial.suggest_int('n_neighbors', 1, 20),\n",
        "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
        "            'algorithm': trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "            'p': trial.suggest_categorical('p', [1, 2])  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "        }\n",
        "\n",
        "        knn = KNeighborsRegressor(**params)\n",
        "        mse_scores = -cross_val_score(knn, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = KNNRegressor_Optuna(X, y)\n",
        "print(f\"K-Nearest Neighbors Regressor RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")"
      ],
      "metadata": {
        "id": "Gz1oIPXT5f44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mutliple Optuna Model"
      ],
      "metadata": {
        "id": "04uguT-W5j26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "def Optuna_Hyperparameter_tuning(X, y):\n",
        "    def objective(trial, X, y):\n",
        "        regressor = trial.suggest_categorical(\"regressor\", ['RandomForest', 'XGB'])\n",
        "\n",
        "        if regressor == \"RandomForest\":\n",
        "            rf_params = {\n",
        "                'n_estimators': trial.suggest_int(\"rf_n_estimators\", 100, 1000, step=100),\n",
        "                'max_depth': trial.suggest_int(\"rf_max_depth\", 3, 20),\n",
        "                'min_samples_split': trial.suggest_int(\"rf_min_samples_split\", 2, 20),\n",
        "                'min_samples_leaf': trial.suggest_int(\"rf_min_samples_leaf\", 1, 20),\n",
        "                'max_features': trial.suggest_categorical(\"rf_max_features\", ['auto', 'sqrt', 'log2']),\n",
        "                'random_state': 42,\n",
        "                'n_jobs': -1\n",
        "            }\n",
        "            reg = RandomForestRegressor(**rf_params)\n",
        "\n",
        "        else:\n",
        "            xgb_params = {\n",
        "                'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
        "                'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
        "                'gamma': trial.suggest_float('xgb_gamma', 1e-8, 1.0, log=True),\n",
        "                'min_child_weight': trial.suggest_int('xgb_min_child_weight', 1, 300),\n",
        "                'reg_alpha': trial.suggest_float('xgb_reg_alpha', 1e-8, 1.0, log=True),\n",
        "                'reg_lambda': trial.suggest_float('xgb_reg_lambda', 1e-8, 1.0, log=True),\n",
        "                'random_state': 42,\n",
        "                'n_jobs': -1\n",
        "            }\n",
        "            reg = XGBRegressor(**xgb_params)\n",
        "\n",
        "        mse_scores = -cross_val_score(reg, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        rmse_scores = np.sqrt(mse_scores)\n",
        "        return rmse_scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial=trial, X=X, y=y), n_trials=100)\n",
        "    trial = study.best_trial\n",
        "    return trial\n",
        "\n",
        "result = Optuna_Hyperparameter_tuning(X=X, y=y)\n",
        "print(f\"RMSE: {result.value}\")\n",
        "print(f\"Best Hyperparameters: {result.params}\")"
      ],
      "metadata": {
        "id": "jdB38QMh5hzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}