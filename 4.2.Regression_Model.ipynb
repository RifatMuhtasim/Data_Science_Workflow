{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnoEpr8eBkGP8cJCOmrG5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/Data_Science_Workflow/blob/main/4.2.Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Machine Learning Model"
      ],
      "metadata": {
        "id": "DjvA4awtN5HF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Regression Model are:\n",
        "1. Linear Regression\n",
        "2. Decision Tree Regressor\n",
        "3. Random Forest Regressor\n",
        "4. XGB Regressor\n",
        "5. SVM Regressor\n",
        "6. K-Nearest Neighbors Regressor\n",
        "6. Deep Learning"
      ],
      "metadata": {
        "id": "01gVUEF-TowM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import math"
      ],
      "metadata": {
        "id": "bO_7-CfGcvHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "ttZVhQAGDdmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnA9LtxADWzl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = lr_model.predict(X_train)\n",
        "y_val_pred = lr_model.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"Linear Regression:\")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Regressor"
      ],
      "metadata": {
        "id": "SUziDRaJGxZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "decision_tree = DecisionTreeRegressor()\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = decision_tree.predict(X_train)\n",
        "y_val_pred = decision_tree.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"Decision Tree Regressor: \")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ],
      "metadata": {
        "id": "dTns_DLQG2oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Regressor"
      ],
      "metadata": {
        "id": "Hq4OHTZ5dVwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random_forest = RandomForestRegressor()\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = random_forest.predict(X_train)\n",
        "y_val_pred = random_forest.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"Random Forest Regressor: \")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ],
      "metadata": {
        "id": "9RtvYsYVdU5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Random forest to solve the Decision Tree High Variance Overfit problem. Using Random Forest i create a Low variance to our dataset."
      ],
      "metadata": {
        "id": "TQMU768VfR2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Regressor"
      ],
      "metadata": {
        "id": "V6sS4jbCKm1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm = SVR()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = svm.predict(X_train)\n",
        "y_val_pred = svm.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"SVM Regressor: \")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ],
      "metadata": {
        "id": "GS8K3f_DKmV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors Regressor"
      ],
      "metadata": {
        "id": "ckEfDDDv7YDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = knn.predict(X_train)\n",
        "y_val_pred = knn.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"K-Nearest Neighbors Regressor: \")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ],
      "metadata": {
        "id": "3AtP8aYl7b3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB Regressor"
      ],
      "metadata": {
        "id": "Hfi1aA-2KAXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor()\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = xgb.predict(X_train)\n",
        "y_val_pred = xgb.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"XGB Regressor: \")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ],
      "metadata": {
        "id": "UOAX4k_wffJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Neural Network"
      ],
      "metadata": {
        "id": "x4ax675MN__z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "ifPU4YhjZMzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "dl_model = Sequential([\n",
        "  Dense(24, input_shape=(X_train.shape[1], ), activation='relu'),\n",
        "  Dense(12, activation='relu'),\n",
        "  Dense(1)\n",
        "])\n",
        "\n",
        "dl_model.compile(optimizer='adam', loss='mean_squared_error' , metrics=['mean_absolute_error'])\n",
        "print(dl_model.summary())"
      ],
      "metadata": {
        "id": "gbJHiF6eZOBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with validation data\n",
        "X_train_fit, X_val_fit, y_train_fit, y_val_fit = train_test_split(X_train, y_train, test_size = 0.20)\n",
        "\n",
        "history = dl_model.fit(X_train_fit, y_train_fit, validation_data=(X_val_fit, y_val_fit), epochs=50, verbose=1)\n",
        "\n",
        "# Extract loss and accuracy values of the last epoch\n",
        "last_epoch_loss = history.history['loss'][-1]\n",
        "last_epoch_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "# Extract loss and mean absolute error values of the last epoch\n",
        "last_epoch_loss = history.history['loss'][-1]\n",
        "last_epoch_val_loss = history.history['val_loss'][-1]\n",
        "last_epoch_mae = history.history['mean_absolute_error'][-1]\n",
        "last_epoch_val_mae = history.history['val_mean_absolute_error'][-1]\n",
        "\n",
        "print(\"Last Epoch Loss (Training):\", last_epoch_loss)\n",
        "print(\"Last Epoch Loss (Validation):\", last_epoch_val_loss)\n",
        "print(\"Last Epoch Mean Absolute Error (Training):\", last_epoch_mae)\n",
        "print(\"Last Epoch Mean Absolute Error (Validation):\", last_epoch_val_mae)"
      ],
      "metadata": {
        "id": "Vz46RXaamfhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = dl_model.predict(X_train)\n",
        "y_val_pred = dl_model.predict(X_val)\n",
        "\n",
        "# Calculate R-Squared Score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "val_r2 = r2_score(y_val, y_val_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "val_rmse = math.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "\n",
        "print(\"Deep Learning: \")\n",
        "print(\"Train R-squared:\", train_r2)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Validation RMSE:\", val_rmse)"
      ],
      "metadata": {
        "id": "e-TlbzLYndYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Hyperparameter Tuning ( GridSearchCV)"
      ],
      "metadata": {
        "id": "HNca8wLFvw4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def Hyperparameter_tuning(X_train, y_train, model_params):\n",
        "  scores = []\n",
        "\n",
        "  for model, mp in model_params.items():\n",
        "    cv = GridSearchCV(mp['model'], mp['params'], cv=5, scoring='neg_mean_squared_error', return_train_score=False)\n",
        "    cv.fit(X_train, y_train)\n",
        "    scores.append({\n",
        "      \"Model\": model,\n",
        "      \"Best_score\": cv.best_score_,\n",
        "      \"Best_params\": cv.best_params_\n",
        "    })\n",
        "\n",
        "  df = pd.DataFrame(scores, columns=['Model', 'Best_score', 'Best_params'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "6Hc_zlDr2sPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = {\n",
        "    'decision_tree':{\n",
        "        'model': DecisionTreeRegressor(),\n",
        "        'params': {\n",
        "            'max_depth': [None, 5, 10, 15, 20],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['auto', 'sqrt', 'log2']\n",
        "        }\n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model': RandomForestRegressor(),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [None, 10, 20],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['auto', 'sqrt', 'log2']\n",
        "        }\n",
        "    },\n",
        "    'xgb': {\n",
        "        'model': XGBRegressor(),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [3, 5, 7],\n",
        "            'learning_rate': [0.01, 0.1, 0.3],\n",
        "            'subsample': [0.8, 1.0],\n",
        "            'colsample_bytree': [0.8, 1.0]\n",
        "        }\n",
        "    },\n",
        "    'svm':{\n",
        "        'model': SVR(),\n",
        "        'params': {\n",
        "            'kernel': ['linear', 'rbf'],\n",
        "            'C': [0.1, 1, 10],\n",
        "            'gamma': ['scale', 'auto']\n",
        "        }\n",
        "    },\n",
        "    'knn': {\n",
        "        'model': KNeighborsRegressor(),\n",
        "        'params': {\n",
        "            'n_neighbors': [3, 5, 7, 9, 11],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "            'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "results = Hyperparameter_tuning(X_train, y_train, model_params)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "results"
      ],
      "metadata": {
        "id": "Hu8vhfPAv1Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Hyperparameter Tuning for Neural Network"
      ],
      "metadata": {
        "id": "Zk3jbUTObnSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "try:\n",
        "    import kerastuner as kt\n",
        "except:\n",
        "    !pip install --quiet keras-tuner\n",
        "    import kerastuner as kt"
      ],
      "metadata": {
        "id": "8ZbpwrVWc8N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Hyperparameter_tuning_for_neural_network(X_train, y_train, X_val, y_val):\n",
        "    def build_neural_model(hp):\n",
        "        model = Sequential()\n",
        "\n",
        "        counter = 0\n",
        "        for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
        "            if counter == 0:\n",
        "                model.add(\n",
        "                    Dense(\n",
        "                        hp.Int('units' + str(i), min_value=8, max_value=128, step=8),\n",
        "                        activation=hp.Choice('activation' + str(i), values=['relu', 'sigmoid', 'tanh']),\n",
        "                        input_shape=(X_train.shape[1],)\n",
        "                    )\n",
        "                )\n",
        "                model.add(\n",
        "                    Dropout(\n",
        "                        hp.Choice('dropout' + str(i), values=[0.1, 0.2, 0.3])\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                model.add(\n",
        "                    Dense(\n",
        "                        hp.Int('units' + str(i), min_value=8, max_value=128, step=8),\n",
        "                        activation=hp.Choice('activation' + str(i), values=['relu', 'sigmoid', 'tanh'])\n",
        "                    )\n",
        "                )\n",
        "                model.add(\n",
        "                    Dropout(\n",
        "                        hp.Choice('dropout' + str(i), values=[0.1, 0.2, 0.3])\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            counter += 1\n",
        "        model.add(Dense(1))\n",
        "        model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd', 'nadam', 'adadelta']),\n",
        "                      loss='mean_squared_error')\n",
        "\n",
        "        return model\n",
        "\n",
        "    tuner = kt.RandomSearch(build_neural_model,\n",
        "                            objective='val_loss',\n",
        "                            max_trials=3,   # Update\n",
        "                            directory='mydir',\n",
        "                            project_name='final')\n",
        "    tuner.search(X_train, y_train, epochs=5, validation_data=(X_val, y_val))   #Update epochs\n",
        "\n",
        "    # return tuner.get_best_models(num_models=1)[0]\n",
        "    return tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "g4ICNnOzdJEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_fit, X_val_fit, y_train_fit, y_val_fit = train_test_split(X_train, y_train, test_size = 0.20)\n",
        "\n",
        "params = Hyperparameter_tuning_for_neural_network(X_train_fit, y_train_fit, X_val_fit, y_val_fit)\n",
        "params"
      ],
      "metadata": {
        "id": "xjjV33R4dgB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Deep Learning Hyperparameters params"
      ],
      "metadata": {
        "id": "sjFE2RqQK3eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Define the parameters\n",
        "params = {\n",
        "    'num_layers': 4,\n",
        "    'units0': 80,\n",
        "    'activation0': 'sigmoid',\n",
        "    'dropout0': 0.1,\n",
        "    'optimizer': 'sgd',\n",
        "    'units1': 8,\n",
        "    'activation1': 'tanh',\n",
        "    'dropout1': 0.3,\n",
        "    'units2': 40,\n",
        "    'activation2': 'tanh',\n",
        "    'dropout2': 0.3,\n",
        "    'units3': 32,\n",
        "    'activation3': 'tanh',\n",
        "    'dropout3': 0.1,\n",
        "    'units4': 16,\n",
        "    'activation4': 'tanh',\n",
        "    'dropout4': 0.2\n",
        "}\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding layers according to the specified parameters\n",
        "model.add(Dense(units=params['units0'], activation=params['activation0'], input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(rate=params['dropout0']))\n",
        "\n",
        "model.add(Dense(units=params['units1'], activation=params['activation1']))\n",
        "model.add(Dropout(rate=params['dropout1']))\n",
        "\n",
        "model.add(Dense(units=params['units2'], activation=params['activation2']))\n",
        "model.add(Dropout(rate=params['dropout2']))\n",
        "\n",
        "model.add(Dense(units=params['units3'], activation=params['activation3']))\n",
        "model.add(Dropout(rate=params['dropout3']))\n",
        "\n",
        "model.add(Dense(units=params['units4'], activation=params['activation4']))\n",
        "model.add(Dropout(rate=params['dropout4']))\n",
        "\n",
        "# Add the output layer for regression (single neuron, no activation function)\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=SGD(),  # Use SGD optimizer\n",
        "              loss='mean_squared_error',  # Suitable for regression\n",
        "              metrics=['mean_absolute_error'])"
      ],
      "metadata": {
        "id": "yUTE008hLg2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with validation data\n",
        "X_train_fit, X_val_fit, y_train_fit, y_val_fit = train_test_split(X_train, y_train, test_size = 0.20)\n",
        "\n",
        "history = model.fit(X_train_fit, y_train_fit, validation_data=(X_val_fit, y_val_fit), epochs=50, verbose=1)\n",
        "\n",
        "# Extract loss and mean absolute error values of the last epoch\n",
        "last_epoch_loss = history.history['loss'][-1]\n",
        "last_epoch_val_loss = history.history['val_loss'][-1]\n",
        "last_epoch_mae = history.history['mean_absolute_error'][-1]\n",
        "last_epoch_val_mae = history.history['val_mean_absolute_error'][-1]\n",
        "\n",
        "print(\"Last Epoch Loss (Training):\", last_epoch_loss)\n",
        "print(\"Last Epoch Loss (Validation):\", last_epoch_val_loss)\n",
        "print(\"Last Epoch Mean Absolute Error (Training):\", last_epoch_mae)\n",
        "print(\"Last Epoch Mean Absolute Error (Validation):\", last_epoch_val_mae)"
      ],
      "metadata": {
        "id": "FSC7Dn5sK3BN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}