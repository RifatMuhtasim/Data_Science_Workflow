{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe3ZS4kJeDPM21T+FAVby5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/Data_Science_Workflow/blob/main/4.5.Time_Series_Forecast_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ARIMA"
      ],
      "metadata": {
        "id": "6gASx9aqLEZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find p,d,q value"
      ],
      "metadata": {
        "id": "4hHDwB1gLjlo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXDPHuv8EKm9"
      },
      "outputs": [],
      "source": [
        "# Test the ARIMA (p, d, q) value\n",
        "\n",
        "# Adfuller Test\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# H0: It is non stationarity\n",
        "# H1: It is stationarity\n",
        "\n",
        "def Adfuller_test(data):\n",
        "    result = adfuller(data)\n",
        "    p_value = result[1]\n",
        "    labels = [\"ADF Test Statistic\", \"P-Value\", \"Lags Used\", \"Number of Observation Used\"]\n",
        "    for value, label in zip(result, labels):\n",
        "        print(label + \" : \" + str(value))\n",
        "\n",
        "    if p_value > 0.05:\n",
        "        print(\"Fail to Reject the Null Hypothesis. Data is non Stationarity.\")\n",
        "    else:\n",
        "        print(\"Reject the Null Hypothesis. Data is Stationarity.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find D Value\n",
        "\n",
        "def Find_d_value_using_Adfuller_test(dataset, target):\n",
        "    df = dataset.copy()\n",
        "    df.rename(columns={target: 0}, inplace=True)\n",
        "\n",
        "    def AdFuller_test(data):\n",
        "        result = adfuller(data)\n",
        "        p_value = result[1]\n",
        "        return p_value\n",
        "\n",
        "    for i in range(1, df.shape[0]):\n",
        "        df[i] = df[i-1] - df[i-1].shift(1)\n",
        "        p_value = AdFuller_test(df[i].dropna())\n",
        "\n",
        "        if p_value <= 0.05:\n",
        "            print(\"d-value: \", i)\n",
        "            break"
      ],
      "metadata": {
        "id": "-gvvnPCuLOY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find P, Q Value\n",
        "\n",
        "try:\n",
        "    import pmdarima as pm\n",
        "except ImportError:\n",
        "    !pip install --quiet pmdarima\n",
        "    import pmdarima as pm\n",
        "\n",
        "def Find_best_arima_model_params(data):\n",
        "    # Specify the parameter grid to search over\n",
        "    p_values = range(0, 14)  # from 2 to 10\n",
        "    q_values = range(0, 10)   # from 0 to 5\n",
        "\n",
        "    # Perform a grid search over the parameter space\n",
        "    model = pm.auto_arima(data,\n",
        "                          start_p=0,\n",
        "                          start_q=0,\n",
        "                          test='adf',\n",
        "                          max_p=15,\n",
        "                          max_q=10,\n",
        "                          m=0,\n",
        "                          d=4,  # Replace the d-value\n",
        "                          seasonal=False,\n",
        "                          start_P=0,\n",
        "                          D=1,\n",
        "                          trace=True,\n",
        "                          error_action='ignore',\n",
        "                          suppress_warnings=True,\n",
        "                          stepwise=True,\n",
        "                          scoring='mse',  # Use Mean Squared Error for scoring\n",
        "                          n_jobs=-1,      # Utilize all available CPU cores\n",
        "                          p_values=p_values,\n",
        "                          q_values=q_values)\n",
        "\n",
        "    # Print the summary of the best model found\n",
        "    print(model.summary())"
      ],
      "metadata": {
        "id": "vGVoT5J0Lcg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "L_XMvRgpLnnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "model = ARIMA(train_dataset['co2_emissions'], order=(2, 4, 0))\n",
        "model_fit = model.fit()"
      ],
      "metadata": {
        "id": "KC3oLJY2Lozh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_output = model_fit.forecast(steps=10).tolist()\n",
        "forecast_output"
      ],
      "metadata": {
        "id": "GYO1GRDsLrhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_result_df = pd.DataFrame(columns=[\"year\", \"co2_emissions\"])\n",
        "\n",
        "for idx, value in enumerate(forecast_output):\n",
        "    new_df = pd.DataFrame({\n",
        "        \"year\": [idx + 2016],\n",
        "        \"co2_emissions\": [value]\n",
        "    })\n",
        "    pred_result_df = pd.concat([pred_result_df, new_df], ignore_index=True)\n",
        "\n",
        "train_dataset = pd.concat([train_dataset, pred_result_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "yG1uRajzMkRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. SARIMAX"
      ],
      "metadata": {
        "id": "S5ipKFOPMl64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ARIMA value for determine p,d,q\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "model = SARIMAX(df['sales'], order=(0, 1, 0), seasonal_order= (0, 1, 0, 12) )\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Forecast the next 10 steps\n",
        "forecast_steps = 10\n",
        "forecast = model_fit.forecast(steps=forecast_steps)\n",
        "\n",
        "# Print the forecasted values\n",
        "print(\"Forecasted values for the next 10 steps:\")\n",
        "print(forecast)"
      ],
      "metadata": {
        "id": "R8xNNyMYMnRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. FBProphet"
      ],
      "metadata": {
        "id": "KHOIwuyqNVqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet import Prophet\n",
        "import logging\n",
        "\n",
        "\n",
        "def FBProphet(df, timestamp, target, freq, periods):\n",
        "    missing_forecast_model = Prophet()\n",
        "    # Set the target column 'y' for Prophet\n",
        "    new_df = pd.DataFrame()\n",
        "    new_df['y'] = df[target]\n",
        "    new_df['ds'] = pd.to_datetime(df[timestamp])\n",
        "\n",
        "    # Suppress INFO messages from Prophet\n",
        "    logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "    logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
        "    logging.getLogger('prophet').setLevel(logging.WARNING)\n",
        "\n",
        "    missing_forecast_model.fit(new_df)\n",
        "    if freq == \"M\":\n",
        "        future = missing_forecast_model.make_future_dataframe(periods=periods, freq='M')\n",
        "    elif freq == \"Y\":\n",
        "        future = missing_forecast_model.make_future_dataframe(periods=periods, freq='Y')\n",
        "    else:\n",
        "        future = missing_forecast_model.make_future_dataframe(periods=periods)\n",
        "\n",
        "    forecast = missing_forecast_model.predict(future)\n",
        "    # Extract Forecast Values\n",
        "    forecast_values = forecast['yhat'][-periods:].tolist()\n",
        "    return forecast_values\n",
        "\n",
        "\n",
        "forecast = FBProphet(df, timestamp= \"month\", target= \"sales\", freq=\"M\", periods=10)\n",
        "forecast"
      ],
      "metadata": {
        "id": "rZBNJ1uGNZOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_months = []\n",
        "forecast_values = []\n",
        "last_month = df['month'].iloc[-1]\n",
        "\n",
        "for index, value in enumerate(forecast):\n",
        "    forecast_month = last_month + pd.DateOffset(months=1+index)\n",
        "    forecast_value = value\n",
        "    forecast_months.append(forecast_month)\n",
        "    forecast_values.append(forecast_value)\n",
        "\n",
        "forecast_data = pd.DataFrame({'month': forecast_months, 'sales': forecast_values})"
      ],
      "metadata": {
        "id": "g7dNn0LvNpWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. LSTM Univariate"
      ],
      "metadata": {
        "id": "m9b4wZ4ZNqb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "RsIcfVTdOaZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Prepare_data(timeseries_data, n_features):\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(timeseries_data)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_features\n",
        "\n",
        "        if end_ix > len(timeseries_data) - 1:\n",
        "            break\n",
        "\n",
        "        # Gather Input and Output Parts of the pattern\n",
        "        seq_X, seq_y = timeseries_data[i: end_ix], timeseries_data[end_ix]\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "pveKiQIuNt1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_data = train_dataset[\"co2_emissions\"]\n",
        "n_steps = 5\n",
        "X_train, y_train = Prepare_data(timeseries_data, n_steps)\n",
        "n_features = 1\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features ))"
      ],
      "metadata": {
        "id": "ys7vrZ_GOP-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building LSTM Model"
      ],
      "metadata": {
        "id": "MY1q5GK6OW7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(n_steps, n_features), activation=\"relu\", return_sequences=True),\n",
        "    LSTM(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "id": "-_MxAPDMOY9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.fit(X_train, y_train, epochs=1000, verbose=0)\n",
        "\n",
        "# Extract loss and accuracy values of the last epoch\n",
        "last_epoch_loss = history.history['loss'][-1]\n",
        "print(\"Last Epoch Loss:\", last_epoch_loss)"
      ],
      "metadata": {
        "id": "xT5R32MKOfbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "aJ5OgHM4OnEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_Prediction(lstm_model, timeseries_data, n_steps, n_features, num_of_predictions):\n",
        "    lstm_output = []\n",
        "    timeseries_array = np.array(timeseries_data)\n",
        "\n",
        "    for i in range(num_of_predictions):\n",
        "        x_input = np.array(timeseries_array[-n_steps:])\n",
        "        print(f\"{i+2016} year input: {x_input}\")\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        y_pred = lstm_model.predict(x_input, verbose=0)\n",
        "        print(f\"{i+2016} year output: {y_pred[0][0]}\")\n",
        "        lstm_output.append(y_pred[0][0])\n",
        "        timeseries_array = np.append(timeseries_array, y_pred[0][0])\n",
        "\n",
        "    return lstm_output"
      ],
      "metadata": {
        "id": "DYWVG_-5Ooaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_output = LSTM_Prediction(lstm_model, timeseries_data, n_steps, n_features, 10)\n",
        "\n",
        "pred_result_df = pd.DataFrame(columns=[\"year\", \"co2_emissions\"])\n",
        "\n",
        "for idx, value in enumerate(lstm_output):\n",
        "    new_df = pd.DataFrame({\n",
        "        \"year\": [idx + 2016],\n",
        "        \"co2_emissions\": [value]\n",
        "    })\n",
        "    pred_result_df = pd.concat([pred_result_df, new_df], ignore_index=True)\n",
        "\n",
        "train_dataset = pd.concat([train_dataset, pred_result_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "JY8a7h2MOrB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. LSTM Multivariate"
      ],
      "metadata": {
        "id": "EdVFY6g_O0Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time Series Split\n",
        "\n",
        "win_length = 3\n",
        "num_features = 12\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = TimeseriesGenerator(X_train, y_train, length=win_length)\n",
        "X_train_gen = train_generator[0][0]\n",
        "y_train_gen = train_generator[0][1]"
      ],
      "metadata": {
        "id": "AsdlF28xO78J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(win_length, num_features), activation=\"relu\", return_sequences=True),\n",
        "    LSTM(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "id": "CdkcrdYGPK08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.fit(X_train_gen, y_train_gen, epochs=1000, verbose=0)\n",
        "\n",
        "# Extract loss and accuracy values of the last epoch\n",
        "last_epoch_loss = history.history['loss'][-1]\n",
        "print(\"Last Epoch Loss:\", last_epoch_loss)"
      ],
      "metadata": {
        "id": "m3BnAiXCPNPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_step = 10\n",
        "forecast = lstm_model.predict(X_train_gen[-future_step: ])\n",
        "forecast"
      ],
      "metadata": {
        "id": "nHUk3_jvPTLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}