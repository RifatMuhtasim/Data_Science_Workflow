{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu5LUPC129joO1XTv1G+gR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/Data_Science_Workflow/blob/main/3.5.Encode_and_Scaled_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Encode categorical variables"
      ],
      "metadata": {
        "id": "63Z7P0gH2uqt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX3U_gKS2X0T"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoding\n",
        "\n",
        "df = pd.get_dummies(data=df, columns=['Country Name'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding (only use in label)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "country_label_encoder = LabelEncoder()\n",
        "country_label_encoder.fit(sample_submission['Country Name'])\n",
        "train['Country Name'] = country_label_encoder.transform(train['Country Name'])\n",
        "test['Country Name'] = country_label_encoder.transform(test['Country Name'])"
      ],
      "metadata": {
        "id": "KCRy6ogE2wws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal Encoding (For Features)\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "category_order = [\"Low\", \"Medium\", \"High\"]\n",
        "category_encoder = OrdinalEncoder(categories=[category_order])\n",
        "category_encoder.fit(sample_submission['pay'])\n",
        "train['pay'] = category_encoder.transform(train['pay'])\n",
        "test['pay'] = category_encoder.transform(test['pay'])"
      ],
      "metadata": {
        "id": "z_ZjJYx92yxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Handling Class Imbalance (for Classification)"
      ],
      "metadata": {
        "id": "Q01KJLWX3dK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle Imbalance dataset using SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "smote = SMOTE(sampling_strategy=\"minority\")\n",
        "X_train_smote,  y_train_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "b9umFp6R3riO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling\n",
        "\n",
        "df_churn0 = df[df['Churn'] == 0]\n",
        "df_churn1 = df[df['Churn'] == 1]\n",
        "df_under0 = df_churn0.sample(len(df_churn1))\n",
        "df = pd.concat([df_churn1, df_under0], axis=\"rows\")\n",
        "df['Churn'].value_counts()"
      ],
      "metadata": {
        "id": "rr5XHYYt3ttt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling\n",
        "from imblearn.combine import SMOTETmoek\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "smk = SMOTETmoek()\n",
        "X_train_smk, y_train_res = smk.fit_sample(X_train, y_train)"
      ],
      "metadata": {
        "id": "pHU1WSOK3vce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Scaled Numerical Features"
      ],
      "metadata": {
        "id": "DqZycgVn3C7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "standard_scaler.fit(X_train)\n",
        "X_train_scaled =  standard_scaler.transform(X_train)\n",
        "X_test_scaled = standard_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "4ZIkWoTT3GeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method scales the features so that they have a mean of 0 and a standard deviation of 1. It preserves the shape of the original distribution but centers it around 0. <br>\n",
        "Formula: $z=\\frac{x-mean}{std}$"
      ],
      "metadata": {
        "id": "ObQPTxU-3SGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization - MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "minmax_scaler.fit(X_train)\n",
        "X_train_scaled =  minmax_scaler.transform(X_train)\n",
        "X_test_scaled = minmax_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "TgHusCYR3Qfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method scales the features to a fixed range, typically between 0 and 1. It's useful when the data needs to be bound within a specific range. <br>\n",
        "Formula: $z=\\frac{x-x_{min}}{x_{max} - x_{min}}$"
      ],
      "metadata": {
        "id": "lZ1LiCYP3U5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RobustScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled =  scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "OnczNmNG3W3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}