{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/Data_Science_Workflow/blob/main/3.3.Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Identify Important Features"
      ],
      "metadata": {
        "id": "sy4JMelLxkd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variance Threshold"
      ],
      "metadata": {
        "id": "HXE8mtu3-j4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa1o6NRS7-yQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "numerical_df = train_df.select_dtypes(include=['int', 'float'])\n",
        "variance_threshold = VarianceThreshold(threshold=0.1)\n",
        "variance_threshold.fit(numerical_df)\n",
        "support_array = variance_threshold.get_support()\n",
        "constant_columns = numerical_df.columns[~support_array]\n",
        "print(\"Constant columns:\", constant_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select Features using Mutual Info Classifiction\n",
        "- Target Variable: Is categorical, like in classification tasks (e.g., predicting if a customer will churn or not).\n",
        "\n",
        "- Features: Can be numerical, categorical, or a mix of both."
      ],
      "metadata": {
        "id": "zy6VhPkHAw4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "\n",
        "# Calculate mutual information\n",
        "mutual_info = mutual_info_classif(X, y)\n",
        "mutual_info = pd.Series(mutual_info, index=X.columns)\n",
        "\n",
        "# Sort mutual information values in descending order\n",
        "mutual_info = mutual_info.sort_values(ascending=False)\n",
        "\n",
        "# Display the sorted mutual information\n",
        "mutual_info.reset_index()"
      ],
      "metadata": {
        "id": "KO2w8GEHAqkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select Features using Mutual Info Regression\n",
        "- Target Variable: Is numerical, such as predicting house prices, sales figures, or any other continuous variable.\n",
        "\n",
        "- Features: Can be a mix of numerical and categorical.\n"
      ],
      "metadata": {
        "id": "UJ2cHbWbDDOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "\n",
        "# Assuming X and y are defined and contain your features and target variable\n",
        "mutual_info = mutual_info_regression(X, y)\n",
        "\n",
        "# Create a pandas Series to hold the mutual information scores\n",
        "mutual_info_series = pd.Series(mutual_info, index=X.columns)\n",
        "\n",
        "# Sort the mutual information scores in descending order\n",
        "mutual_info_sorted = mutual_info_series.sort_values(ascending=False)\n",
        "\n",
        "# Display the sorted mutual information scores\n",
        "mutual_info_sorted.reset_index()"
      ],
      "metadata": {
        "id": "h4uWLlZpDJeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select Feature using Chi2 Statistical Analysis\n",
        "You would apply the chi-squared feature selection method when:\n",
        "\n",
        "- Target Variable: Is categorical, such as class labels in a classification problem.\n",
        "\n",
        "- Features: Are numerical, specifically discrete values or counts, rather than continuous values."
      ],
      "metadata": {
        "id": "xCKSiqjFDV4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "\n",
        "f_p_values = chi2(X, y)\n",
        "p_values = pd.Series(f_p_values[0])\n",
        "p_values.index = X.columns\n",
        "p_values.sort_values(ascending=False).reset_index()"
      ],
      "metadata": {
        "id": "P8UeLmhhDitB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This score should be used to evaluate categorical variables in classification task"
      ],
      "metadata": {
        "id": "Ohl8RXqON8N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranked Best feature using Univariate Analysis\n",
        "- Your features are numerical (discrete counts or binary).\n",
        "\n",
        "- Your target variable is categorical."
      ],
      "metadata": {
        "id": "IRYcgoHnEDNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "\n",
        "order_ranked_columns = SelectKBest(score_func=chi2, k='all')\n",
        "order_ranked_features = order_ranked_columns.fit(X, y)\n",
        "\n",
        "df_scores = pd.DataFrame(order_ranked_features.scores_, columns=['score'])\n",
        "df_columns = pd.DataFrame(X.columns)\n",
        "feature_rank = pd.concat([df_columns, df_scores], axis=\"columns\")\n",
        "featrue_rank.sort_values(\"score\", ascending=False)"
      ],
      "metadata": {
        "id": "3wwB24YvEj5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranked Best Features using ANOVA\n",
        "- Feature Numerical but Target Categorical"
      ],
      "metadata": {
        "id": "5CjVGPltTebb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "\n",
        "order_ranked_columns = SelectKBest(f_classif, k='all')\n",
        "order_ranked_features = order_ranked_columns.fit(X, y)\n",
        "\n",
        "df_scores = pd.DataFrame(order_ranked_features.scores_, columns=['score'])\n",
        "df_columns = pd.DataFrame(X.columns)\n",
        "feature_rank = pd.concat([df_columns, df_scores], axis=\"columns\")\n",
        "feature_rank.sort_values(\"score\", ascending=False)"
      ],
      "metadata": {
        "id": "5ZdXQEouTiuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select Features using ExtraTreesClassifier\n",
        "When using an ExtraTreesClassifier, examining feature importance can be incredibly insightful."
      ],
      "metadata": {
        "id": "yUZ3c4s8F7ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "X = df.drop(['output'], axis=\"columns\")\n",
        "y = df['output']\n",
        "\n",
        "# Assuming you have your data loaded in X_train and y_train\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Extract feature importances\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display the feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "feature_importance_df"
      ],
      "metadata": {
        "id": "JRWm39YHGtAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recursive Feature Elimination (RFE):\n",
        "Recursive Feature Elimination (RFE) is a feature selection technique in machine learning. Here's how it works:\n",
        "\n",
        "How RFE Works\n",
        "Initial Model Fitting: It starts by training a model (e.g., logistic regression, decision tree) on the entire dataset.\n",
        "\n",
        "Ranking Features: The model assigns an importance score to each feature.\n",
        "\n",
        "Eliminating Least Important Features: The least important features are removed.\n",
        "\n",
        "Repeating the Process: The process is repeated recursively with the remaining features until the desired number of features is selected."
      ],
      "metadata": {
        "id": "lPgc7Nr0RnEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "rfe = RFE(model, n_features_to_select=5)\n",
        "X_selected = rfe.fit_transform(X, y)\n",
        "# Get the ranking of features\n",
        "ranking = rfe.ranking_\n",
        "\n",
        "# Create a DataFrame to view the selected features and their rankings\n",
        "selected_features = pd.DataFrame({'Feature': X.columns, 'Ranking': ranking})\n",
        "selected_features = selected_features.sort_values('Ranking', ascending = True)\n",
        "display(selected_features)"
      ],
      "metadata": {
        "id": "DMT-NgbwRn8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of Recursive Feature Elimination (RFE), a ranking of 1 indicates the most important feature. Essentially, the lower the ranking number, the more significant the feature. So, a ranking of 1 is excellent, while 30 would be much less influential. Got a lot riding on those top-ranked features!"
      ],
      "metadata": {
        "id": "lVd_3aco9vOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Remove Features"
      ],
      "metadata": {
        "id": "LdE6ixTBxoZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove columns\n",
        "\n",
        "remove_columns_list = ['B',  'C']\n",
        "df = my_df.drop(remove_columns_list, axis=1)"
      ],
      "metadata": {
        "id": "4vKYo8CGxqJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}